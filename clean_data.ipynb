{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d793c0a48251aa2"
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import date_range_data_extractor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:42:42.592926700Z",
     "start_time": "2023-11-28T10:42:42.305798Z"
    }
   },
   "id": "56605910302ac169"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0c7e97707f1c9f4"
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [],
   "source": [
    "Y = '2022'\n",
    "quoter = 4\n",
    "\n",
    "if quoter == 1:\n",
    "    Q = ['Q1','01-01','03-31']\n",
    "elif quoter == 2:\n",
    "    Q = ['Q2','04-01','06-30']\n",
    "elif quoter == 3:\n",
    "    Q = ['Q3','07-01','09-30']\n",
    "elif quoter == 4:\n",
    "    Q = ['Q4','10-01','12-31']\n",
    "\n",
    "from_date = f'{Y}-{Q[1]}' # ex: '2021-01-01'\n",
    "to_date = f'{Y}-{Q[2]}' # ex: '2021-03-31'\n",
    "output_filename = f'{Y}-{Q[0]}_seconds.csv' # ex: '2021-Q1_seconds.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:42:42.615831500Z",
     "start_time": "2023-11-28T10:42:42.327746300Z"
    }
   },
   "id": "4c881350b100140f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5c1e8a1ac234188"
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:44:21.237435200Z",
     "start_time": "2023-11-28T10:42:42.342232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file 2022-10-01.csv...\n",
      "Loading file 2022-10-02.csv...\n",
      "Loading file 2022-10-03.csv...\n",
      "Loading file 2022-10-04.csv...\n",
      "Loading file 2022-10-05.csv...\n",
      "Loading file 2022-10-06.csv...\n",
      "Loading file 2022-10-07.csv...\n",
      "Loading file 2022-10-08.csv...\n",
      "Loading file 2022-10-09.csv...\n",
      "Loading file 2022-10-10.csv...\n",
      "Loading file 2022-10-11.csv...\n",
      "Loading file 2022-10-12.csv...\n",
      "Loading file 2022-10-13.csv...\n",
      "Loading file 2022-10-14.csv...\n",
      "Loading file 2022-10-15.csv...\n",
      "Loading file 2022-10-16.csv...\n",
      "Loading file 2022-10-17.csv...\n",
      "Loading file 2022-10-18.csv...\n",
      "Loading file 2022-10-19.csv...\n",
      "Loading file 2022-10-20.csv...\n",
      "Loading file 2022-10-21.csv...\n",
      "Loading file 2022-10-22.csv...\n",
      "Loading file 2022-10-23.csv...\n",
      "Loading file 2022-10-24.csv...\n",
      "Loading file 2022-10-25.csv...\n",
      "Loading file 2022-10-26.csv...\n",
      "Loading file 2022-10-27.csv...\n",
      "Loading file 2022-10-28.csv...\n",
      "Loading file 2022-10-29.csv...\n",
      "Loading file 2022-10-30.csv...\n",
      "Loading file 2022-10-31.csv...\n",
      "Loading file 2022-11-01.csv...\n",
      "Loading file 2022-11-02.csv...\n",
      "Loading file 2022-11-03.csv...\n",
      "Loading file 2022-11-04.csv...\n",
      "Loading file 2022-11-05.csv...\n",
      "Loading file 2022-11-06.csv...\n",
      "Loading file 2022-11-07.csv...\n",
      "Loading file 2022-11-08.csv...\n",
      "Loading file 2022-11-09.csv...\n",
      "Loading file 2022-11-10.csv...\n",
      "Loading file 2022-11-11.csv...\n",
      "Loading file 2022-11-12.csv...\n",
      "Loading file 2022-11-13.csv...\n",
      "Loading file 2022-11-14.csv...\n",
      "Loading file 2022-11-15.csv...\n",
      "Loading file 2022-11-16.csv...\n",
      "Loading file 2022-11-17.csv...\n",
      "Loading file 2022-11-18.csv...\n",
      "Loading file 2022-11-19.csv...\n",
      "Loading file 2022-11-20.csv...\n",
      "Loading file 2022-11-21.csv...\n",
      "Loading file 2022-11-22.csv...\n",
      "Loading file 2022-11-23.csv...\n",
      "Loading file 2022-11-24.csv...\n",
      "Loading file 2022-11-25.csv...\n",
      "Loading file 2022-11-26.csv...\n",
      "Loading file 2022-11-27.csv...\n",
      "Loading file 2022-11-28.csv...\n",
      "Loading file 2022-11-29.csv...\n",
      "Loading file 2022-11-30.csv...\n",
      "Loading file 2022-12-01.csv...\n",
      "Loading file 2022-12-02.csv...\n",
      "Loading file 2022-12-03.csv...\n",
      "Loading file 2022-12-04.csv...\n",
      "Loading file 2022-12-05.csv...\n",
      "Loading file 2022-12-06.csv...\n",
      "Loading file 2022-12-07.csv...\n",
      "Loading file 2022-12-08.csv...\n",
      "Loading file 2022-12-09.csv...\n",
      "Loading file 2022-12-10.csv...\n",
      "Loading file 2022-12-11.csv...\n",
      "Loading file 2022-12-12.csv...\n",
      "Loading file 2022-12-13.csv...\n",
      "Loading file 2022-12-14.csv...\n",
      "Loading file 2022-12-15.csv...\n",
      "Loading file 2022-12-16.csv...\n",
      "Loading file 2022-12-17.csv...\n",
      "Loading file 2022-12-18.csv...\n",
      "Loading file 2022-12-19.csv...\n",
      "Loading file 2022-12-20.csv...\n",
      "Loading file 2022-12-21.csv...\n",
      "Loading file 2022-12-22.csv...\n",
      "Loading file 2022-12-23.csv...\n",
      "Loading file 2022-12-24.csv...\n",
      "Loading file 2022-12-25.csv...\n",
      "Loading file 2022-12-26.csv...\n",
      "Loading file 2022-12-27.csv...\n",
      "Loading file 2022-12-28.csv...\n",
      "Loading file 2022-12-29.csv...\n",
      "Loading file 2022-12-30.csv...\n",
      "Loading file 2022-12-31.csv...\n"
     ]
    }
   ],
   "source": [
    "# Extract data from csv files.\n",
    "data_extractor = date_range_data_extractor.DateRangeDataExtractor()\n",
    "data_extractor.extract_data(r'./files/', from_date, to_date)\n",
    "data = data_extractor.data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Concatenate data and show info"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0b1d73b35a75b7f"
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79505934 entries, 0 to 79505933\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   Time    object \n",
      " 1   Value   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 1.2+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(data, ignore_index=True, join='inner')\n",
    "print(df.info(), end='\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:44:23.647005100Z",
     "start_time": "2023-11-28T10:44:21.266360100Z"
    }
   },
   "id": "b4b0b868419679a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scale data\n",
    "Change the Time value to datetime format and filter the data to whole seconds and remove all other values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35345f6b33960fc5"
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Time     Value\n",
      "0 2022-10-01 00:00:00  49.98771\n",
      "1 2022-10-01 00:00:01  49.98478\n",
      "2 2022-10-01 00:00:02  49.98796\n",
      "3 2022-10-01 00:00:03  49.98621\n",
      "4 2022-10-01 00:00:04  49.98732\n"
     ]
    }
   ],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df = df[df['Time'].dt.microsecond == 0]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:08.212605200Z",
     "start_time": "2023-11-28T10:44:23.654981300Z"
    }
   },
   "id": "3128bda800186933"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add timezone to data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0d04c2813bbd4a5"
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Time     Value\n",
      "0 2022-10-01 00:00:00+03:00  49.98771\n",
      "1 2022-10-01 00:00:01+03:00  49.98478\n",
      "2 2022-10-01 00:00:02+03:00  49.98796\n",
      "3 2022-10-01 00:00:03+03:00  49.98621\n",
      "4 2022-10-01 00:00:04+03:00  49.98732\n"
     ]
    }
   ],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time']).dt.tz_localize('Europe/Helsinki', ambiguous='infer')\n",
    "print(df.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:13.536734400Z",
     "start_time": "2023-11-28T10:46:08.217595Z"
    }
   },
   "id": "658d4b88334e0c7a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add extra hour"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25896d47c8c4f042"
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file 2023-01-01.csv...\n"
     ]
    }
   ],
   "source": [
    "if quoter == 4:\n",
    "    data_extractor_extra = date_range_data_extractor.DateRangeDataExtractor()\n",
    "    data_extractor_extra.extract_data(r'./files/', f'{str(int(Y) + 1)}-01-01', f'{str(int(Y) + 1)}-01-01')\n",
    "    extra_data = data_extractor_extra.data\n",
    "    edf = pd.concat(extra_data, ignore_index=True, join='inner')\n",
    "    edf['Time'] = pd.to_datetime(edf['Time'])\n",
    "    edf = edf[edf['Time'].dt.microsecond == 0]\n",
    "    edf.reset_index(drop=True, inplace=True)\n",
    "    edf['Time'] = pd.to_datetime(edf['Time']).dt.tz_localize('Europe/Helsinki', ambiguous='infer')\n",
    "    edf = edf[edf['Time'] <= f'{str(int(Y) + 1)}-01-01 01:00:00']\n",
    "    df = pd.concat([df, edf])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    print('Skipping!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:15.949741900Z",
     "start_time": "2023-11-28T10:46:13.544713200Z"
    }
   },
   "id": "dff2772d2e753b1f"
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7954202 entries, 0 to 7954201\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype                          \n",
      "---  ------  -----                          \n",
      " 0   Time    datetime64[ns, Europe/Helsinki]\n",
      " 1   Value   float64                        \n",
      "dtypes: datetime64[ns, Europe/Helsinki](1), float64(1)\n",
      "memory usage: 121.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:15.971681100Z",
     "start_time": "2023-11-28T10:46:15.957718900Z"
    }
   },
   "id": "7e480c1e49e2ad4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyze integrity of data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7ded2bd4c34f093"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check and drop duplicates if any"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce28ba9a762671f2"
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: \n",
      "11\n",
      "                             Time     Value\n",
      "3601    2022-10-01 01:00:00+03:00  49.96100\n",
      "14403   2022-10-01 04:00:00+03:00  50.01071\n",
      "2684942 2022-11-01 01:00:00+02:00  49.93320\n",
      "2688531 2022-11-01 02:00:00+02:00  50.05831\n",
      "2692132 2022-11-01 03:00:00+02:00  50.03057\n",
      "2695733 2022-11-01 04:00:00+02:00  50.05378\n",
      "5276480 2022-12-01 01:00:00+02:00  49.95108\n",
      "5280081 2022-12-01 02:00:00+02:00  49.99757\n",
      "5283682 2022-12-01 03:00:00+02:00  50.03777\n",
      "5287283 2022-12-01 04:00:00+02:00  50.04827\n",
      "7954201 2023-01-01 01:00:00+02:00  49.95928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duplicated_rows = df[df.duplicated()]\n",
    "num_duplicated = len(duplicated_rows)\n",
    "print(f'Duplicates: \\n{num_duplicated}\\n{duplicated_rows}', end='\\n\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:18.885968600Z",
     "start_time": "2023-11-28T10:46:15.976667100Z"
    }
   },
   "id": "518577c5a5102b06"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove duplicates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fce57f047da4c1bd"
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:21.925871500Z",
     "start_time": "2023-11-28T10:46:18.890955500Z"
    }
   },
   "id": "31c4e11ed626341"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Find duplicates in date"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fcf67165c864fa1"
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in Time column: \n",
      "4\n",
      "                           Time     Value\n",
      "7201  2022-10-01 02:00:00+03:00  50.01313\n",
      "7202  2022-10-01 02:00:00+03:00  50.01300\n",
      "10801 2022-10-01 03:00:00+03:00  49.92700\n",
      "10802 2022-10-01 03:00:00+03:00  49.92590\n"
     ]
    }
   ],
   "source": [
    "duplicated_rows_time = df[df.duplicated(subset=\"Time\", keep=False)]\n",
    "num_duplicated_time = len(duplicated_rows_time)\n",
    "print(f'Duplicates in Time column: \\n{num_duplicated_time}\\n{duplicated_rows_time}', end='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:23.194677100Z",
     "start_time": "2023-11-28T10:46:21.927865100Z"
    }
   },
   "id": "e4e93e062ea15efd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove duplicates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3abf53207780187a"
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='Time')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:24.458281900Z",
     "start_time": "2023-11-28T10:46:23.195673700Z"
    }
   },
   "id": "d0da198db305f804"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Any NaN, Null, 0 or \"\" found in Value."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0b19c4f8f538a62"
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is not a number in value column:: \n",
      "0\n",
      "Is a NULL in value column:: \n",
      "0\n",
      "Zero values in value column: \n",
      "0\n",
      "White spaces in value column: \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "dfNaN = df[df['Value'].isna()]\n",
    "nrNaN = len(dfNaN)\n",
    "dfNull = df[df['Value'].isnull()]\n",
    "nrNull = len(dfNull)\n",
    "dfZeroValues = df[df['Value'] == 0]\n",
    "zeroValues = len(dfZeroValues)\n",
    "dfWhiteSpaces = df[df['Value'] == \"\"]\n",
    "whiteSpaces = len(dfWhiteSpaces)\n",
    "print(f'Is not a number in value column:: \\n{nrNaN}', end='\\n')\n",
    "print(f'Is a NULL in value column:: \\n{nrNull}', end='\\n')\n",
    "print(f'Zero values in value column: \\n{zeroValues}', end='\\n')\n",
    "print(f'White spaces in value column: \\n{whiteSpaces}', end='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:24.521116100Z",
     "start_time": "2023-11-28T10:46:24.463270700Z"
    }
   },
   "id": "4420e2005b519f84"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Finding any missing date in the series of dates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3ec566000febccf"
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [],
   "source": [
    "df.set_index('Time', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:24.583005900Z",
     "start_time": "2023-11-28T10:46:24.525105200Z"
    }
   },
   "id": "390e1b8048ebbef2"
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-01 00:00:00+03:00 \n",
      " 2023-01-01 01:00:00+02:00\n"
     ]
    }
   ],
   "source": [
    "from_date_filter = pd.to_datetime(from_date).tz_localize('Europe/Helsinki')\n",
    "\n",
    "if quoter == 4:\n",
    "    to_date_filter = f'{str(int(Y) + 1)}-01-01 01:00:00+02:00'\n",
    "    to_date_filter = pd.to_datetime(to_date_filter).tz_convert('Europe/Helsinki')\n",
    "else:\n",
    "    to_date_filter = pd.to_datetime(to_date).tz_localize('Europe/Helsinki')\n",
    "    to_date_filter = to_date_filter.replace(hour=23, minute=59, second=59)\n",
    "\n",
    "print(from_date_filter,'\\n',to_date_filter)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:24.596912300Z",
     "start_time": "2023-11-28T10:46:24.555026500Z"
    }
   },
   "id": "8419bff775d5037c"
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing seconds: 1812\n",
      "\n",
      "\n",
      "                           Time  Value\n",
      "7230  2022-10-01 02:00:30+03:00   -1.0\n",
      "50431 2022-10-01 14:00:31+03:00   -1.0\n",
      "50432 2022-10-01 14:00:32+03:00   -1.0\n",
      "50433 2022-10-01 14:00:33+03:00   -1.0\n",
      "50434 2022-10-01 14:00:34+03:00   -1.0\n"
     ]
    }
   ],
   "source": [
    "date_range = pd.date_range(start=from_date_filter, end=to_date_filter, freq='S')\n",
    "missingSeconds = date_range[~date_range.isin(df.index)].value_counts().sum()\n",
    "\n",
    "df = df.reindex(date_range)\n",
    "print(f'Number of missing seconds: {missingSeconds}', end='\\n\\n\\n')\n",
    "df.reset_index(inplace=True, names=\"Time\")\n",
    "df['Value'].fillna(-1, inplace=True)\n",
    "print(df[df['Value']==-1].head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:27.638831500Z",
     "start_time": "2023-11-28T10:46:24.593920900Z"
    }
   },
   "id": "11c01ce38a3399f8"
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Ok\n"
     ]
    }
   ],
   "source": [
    "if missingSeconds == (df[df['Value'] == -1].value_counts().sum()):\n",
    "    print('Test Ok')\n",
    "else:\n",
    "    print('Test Failed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:27.710638100Z",
     "start_time": "2023-11-28T10:46:27.638831500Z"
    }
   },
   "id": "111543e7e575a57b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert to Swedish time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e03a25003ca19247"
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Time     Value\n",
      "0 2022-09-30 23:00:00+02:00  49.98771\n",
      "1 2022-09-30 23:00:01+02:00  49.98478\n",
      "2 2022-09-30 23:00:02+02:00  49.98796\n",
      "3 2022-09-30 23:00:03+02:00  49.98621\n",
      "4 2022-09-30 23:00:04+02:00  49.98732\n",
      "                             Time     Value\n",
      "7955996 2022-12-31 23:59:56+01:00  49.96575\n",
      "7955997 2022-12-31 23:59:57+01:00  49.96507\n",
      "7955998 2022-12-31 23:59:58+01:00  49.96166\n",
      "7955999 2022-12-31 23:59:59+01:00  49.96383\n",
      "7956000 2023-01-01 00:00:00+01:00  49.95928\n"
     ]
    }
   ],
   "source": [
    "df['Time'] = df['Time'].dt.tz_convert('Europe/Stockholm')\n",
    "print(df.head(5))\n",
    "print(df.tail(5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:27.729587900Z",
     "start_time": "2023-11-28T10:46:27.670747Z"
    }
   },
   "id": "3a3b5c1e4223044c"
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Time     Value\n",
      "0 2022-09-30 23:00:00+02:00  49.98771\n",
      "1 2022-09-30 23:00:01+02:00  49.98478\n",
      "2 2022-09-30 23:00:02+02:00  49.98796\n",
      "3 2022-09-30 23:00:03+02:00  49.98621\n",
      "4 2022-09-30 23:00:04+02:00  49.98732\n",
      "                             Time     Value\n",
      "7955995 2022-12-31 23:59:55+01:00  49.96766\n",
      "7955996 2022-12-31 23:59:56+01:00  49.96575\n",
      "7955997 2022-12-31 23:59:57+01:00  49.96507\n",
      "7955998 2022-12-31 23:59:58+01:00  49.96166\n",
      "7955999 2022-12-31 23:59:59+01:00  49.96383\n"
     ]
    }
   ],
   "source": [
    "from_date_filter = pd.to_datetime(from_date).tz_localize('Europe/Stockholm')\n",
    "to_date_filter = pd.to_datetime(to_date).tz_localize('Europe/Stockholm')\n",
    "to_date_filter = to_date_filter.replace(hour=23, minute=59, second=59)\n",
    "if quoter == 1:\n",
    "    df = df[(df['Time'] >= from_date_filter) & (df['Time'] <= to_date_filter)]\n",
    "else:\n",
    "    df = df[df['Time'] <= to_date_filter]\n",
    "print(df.head(5))\n",
    "print(df.tail(5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:28.016800800Z",
     "start_time": "2023-11-28T10:46:27.714629300Z"
    }
   },
   "id": "ddf415cd1652f43"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "150278597b9249c5"
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 \n",
      "One hour will always be removed if your data contains January (3600 seconds).\n"
     ]
    }
   ],
   "source": [
    "if df.Value.count() == len(date_range) :\n",
    "    print('Test passed')\n",
    "else :\n",
    "    print(df.Value.count() - len(date_range), '\\nOne hour will always be removed if your data contains January (3600 seconds).')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:46:28.087638500Z",
     "start_time": "2023-11-28T10:46:28.017798900Z"
    }
   },
   "id": "6abd3d0165b67f99"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c21e456624cb41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save the data to a new csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c98e1ab88a812cf"
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [],
   "source": [
    "folder_name = 'processed_files'\n",
    "file_name = output_filename\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "df.to_csv(file_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:47:56.391446700Z",
     "start_time": "2023-11-28T10:46:28.077645100Z"
    }
   },
   "id": "92eceeb0d5db51a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save to logfile"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ebeefd6040f2468"
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "folder_name = 'log'\n",
    "file_name = 'log.csv'\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "columns = ['Index', 'DateFrom', 'DateTo', 'NULL', 'NaN', 'Exact duplicates', 'Time duplicates', 'Zero Values', 'White Space', 'Added missing seconds']\n",
    "\n",
    "new_data = {'Index': output_filename, 'DateFrom': from_date, 'DateTo': to_date, 'NULL': nrNull, 'NaN': nrNaN, 'Exact duplicates': num_duplicated, 'Time duplicates': num_duplicated_time, 'Zero Values': zeroValues, 'White Space': whiteSpaces, 'Added missing seconds': missingSeconds}\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    log_df = pd.DataFrame(columns=columns)\n",
    "else:\n",
    "    log_df = pd.read_csv(file_path)\n",
    "\n",
    "index_exists = (log_df['Index'] == new_data['Index']).any()\n",
    "\n",
    "if index_exists:\n",
    "    log_df.loc[log_df['Index'] == new_data['Index']] = [new_data[col] for col in columns]\n",
    "else:\n",
    "    new_row = pd.DataFrame([new_data], columns=columns)\n",
    "    log_df = pd.concat([log_df, new_row], ignore_index=True)\n",
    "\n",
    "log_df.to_csv(file_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:47:56.436704800Z",
     "start_time": "2023-11-28T10:47:56.401796200Z"
    }
   },
   "id": "24b9d6dc0210ff17"
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [
    {
     "data": {
      "text/plain": "                  Index    DateFrom      DateTo  NULL  NaN  Exact duplicates  \\\n0   2020-Q1_seconds.csv  2020-01-01  2020-03-31     0    0                12   \n1   2020-Q2_seconds.csv  2020-04-01  2020-06-30     0    0                 9   \n2   2020-Q3_seconds.csv  2020-07-01  2020-09-30     0    0                 7   \n3   2020-Q4_seconds.csv  2020-10-01  2020-12-31     0    0                13   \n4   2021-Q1_seconds.csv  2021-01-01  2021-03-31     0    0                12   \n5   2021-Q2_seconds.csv  2021-04-01  2021-06-30     0    0                11   \n6   2021-Q3_seconds.csv  2021-07-01  2021-09-30     0    0                 9   \n7   2021-Q4_seconds.csv  2021-10-01  2021-12-31     0    0                13   \n8   2022-Q1_seconds.csv  2022-01-01  2022-03-31     0    0                10   \n9   2022-Q2_seconds.csv  2022-04-01  2022-06-30     0    0                 5   \n10  2022-Q3_seconds.csv  2022-07-01  2022-09-30     0    0                 8   \n11  2022-Q4_seconds.csv  2022-10-01  2022-12-31     0    0                11   \n\n    Time duplicates  Zero Values  White Space  Added missing seconds  \n0                 0            0            0                  11939  \n1                 6            0            0                  17708  \n2                 2            0            0                 536994  \n3                 0            0            0                 119584  \n4                 0            0            0                   8304  \n5                 2            0            0                   9535  \n6                 6            0            0                   3218  \n7                 0            0            0                   1762  \n8                 4            0            0                 128146  \n9                14            0            0                   2859  \n10                8            0            0                   3197  \n11                4            0            0                   1812  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Index</th>\n      <th>DateFrom</th>\n      <th>DateTo</th>\n      <th>NULL</th>\n      <th>NaN</th>\n      <th>Exact duplicates</th>\n      <th>Time duplicates</th>\n      <th>Zero Values</th>\n      <th>White Space</th>\n      <th>Added missing seconds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-Q1_seconds.csv</td>\n      <td>2020-01-01</td>\n      <td>2020-03-31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11939</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-Q2_seconds.csv</td>\n      <td>2020-04-01</td>\n      <td>2020-06-30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17708</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-Q3_seconds.csv</td>\n      <td>2020-07-01</td>\n      <td>2020-09-30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>536994</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-Q4_seconds.csv</td>\n      <td>2020-10-01</td>\n      <td>2020-12-31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>119584</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-Q1_seconds.csv</td>\n      <td>2021-01-01</td>\n      <td>2021-03-31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8304</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2021-Q2_seconds.csv</td>\n      <td>2021-04-01</td>\n      <td>2021-06-30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9535</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2021-Q3_seconds.csv</td>\n      <td>2021-07-01</td>\n      <td>2021-09-30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3218</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2021-Q4_seconds.csv</td>\n      <td>2021-10-01</td>\n      <td>2021-12-31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1762</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2022-Q1_seconds.csv</td>\n      <td>2022-01-01</td>\n      <td>2022-03-31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>128146</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2022-Q2_seconds.csv</td>\n      <td>2022-04-01</td>\n      <td>2022-06-30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2859</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2022-Q3_seconds.csv</td>\n      <td>2022-07-01</td>\n      <td>2022-09-30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3197</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2022-Q4_seconds.csv</td>\n      <td>2022-10-01</td>\n      <td>2022-12-31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1812</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(log_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:47:56.466512900Z",
     "start_time": "2023-11-28T10:47:56.424734Z"
    }
   },
   "id": "60694f23c73820f7"
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T10:47:56.486366Z",
     "start_time": "2023-11-28T10:47:56.460529100Z"
    }
   },
   "id": "f84ae64f47f68bfe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
