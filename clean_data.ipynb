{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d793c0a48251aa2"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import date_range_data_extractor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:09:20.307526900Z",
     "start_time": "2023-11-14T12:09:19.920510800Z"
    }
   },
   "id": "56605910302ac169"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0c7e97707f1c9f4"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "Y = '2023'\n",
    "quoter = 3\n",
    "\n",
    "if quoter == 1:\n",
    "    Q = ['Q1','01-01','03-31']\n",
    "elif quoter == 2:\n",
    "    Q = ['Q2','04-01','06-30']\n",
    "elif quoter == 3:\n",
    "    Q = ['Q3','07-01','09-30']\n",
    "elif quoter == 4:\n",
    "    Q = ['Q4','10-01','12-31']\n",
    "\n",
    "from_date = f'{Y}-{Q[1]}' # ex: '2021-01-01'\n",
    "to_date = f'{Y}-{Q[2]}' # ex: '2021-03-31'\n",
    "output_filename = f'{Y}-{Q[0]}_seconds.csv' # ex: '2021-Q1_seconds.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:09:20.386317900Z",
     "start_time": "2023-11-14T12:09:19.947438200Z"
    }
   },
   "id": "4c881350b100140f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5c1e8a1ac234188"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:10:26.454144Z",
     "start_time": "2023-11-14T12:09:19.957614200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file 2023-07-01.csv...\n",
      "Loading file 2023-07-02.csv...\n",
      "Loading file 2023-07-03.csv...\n",
      "Loading file 2023-07-04.csv...\n",
      "Loading file 2023-07-05.csv...\n",
      "Loading file 2023-07-06.csv...\n",
      "Loading file 2023-07-07.csv...\n",
      "Loading file 2023-07-08.csv...\n",
      "Loading file 2023-07-09.csv...\n",
      "Loading file 2023-07-10.csv...\n",
      "Loading file 2023-07-11.csv...\n",
      "Loading file 2023-07-12.csv...\n",
      "Loading file 2023-07-13.csv...\n",
      "Loading file 2023-07-14.csv...\n",
      "Loading file 2023-07-15.csv...\n",
      "Loading file 2023-07-16.csv...\n",
      "Loading file 2023-07-17.csv...\n",
      "Loading file 2023-07-18.csv...\n",
      "Loading file 2023-07-19.csv...\n",
      "Loading file 2023-07-20.csv...\n",
      "Loading file 2023-07-21.csv...\n",
      "Loading file 2023-07-22.csv...\n",
      "Loading file 2023-07-23.csv...\n",
      "Loading file 2023-07-24.csv...\n",
      "Loading file 2023-07-25.csv...\n",
      "Loading file 2023-07-26.csv...\n",
      "Loading file 2023-07-27.csv...\n",
      "Loading file 2023-07-28.csv...\n",
      "Loading file 2023-07-29.csv...\n",
      "Loading file 2023-07-30.csv...\n",
      "Loading file 2023-07-31.csv...\n",
      "Loading file 2023-08-01.csv...\n",
      "Loading file 2023-08-02.csv...\n",
      "Loading file 2023-08-03.csv...\n",
      "Loading file 2023-08-04.csv...\n",
      "Loading file 2023-08-05.csv...\n",
      "Loading file 2023-08-06.csv...\n",
      "Loading file 2023-08-07.csv...\n",
      "Loading file 2023-08-08.csv...\n",
      "Loading file 2023-08-09.csv...\n",
      "Loading file 2023-08-10.csv...\n",
      "Loading file 2023-08-11.csv...\n",
      "Loading file 2023-08-12.csv...\n",
      "Loading file 2023-08-13.csv...\n",
      "Loading file 2023-08-14.csv...\n",
      "Loading file 2023-08-15.csv...\n",
      "Loading file 2023-08-16.csv...\n",
      "Loading file 2023-08-17.csv...\n",
      "Loading file 2023-08-18.csv...\n",
      "Loading file 2023-08-19.csv...\n",
      "Loading file 2023-08-20.csv...\n",
      "Loading file 2023-08-21.csv...\n",
      "Loading file 2023-08-22.csv...\n",
      "Loading file 2023-08-23.csv...\n",
      "Loading file 2023-08-24.csv...\n",
      "Loading file 2023-08-25.csv...\n",
      "Loading file 2023-08-26.csv...\n",
      "Loading file 2023-08-27.csv...\n",
      "Loading file 2023-08-28.csv...\n",
      "Loading file 2023-08-29.csv...\n",
      "Loading file 2023-08-30.csv...\n",
      "Loading file 2023-08-31.csv...\n"
     ]
    }
   ],
   "source": [
    "# Extract data from csv files.\n",
    "data_extractor = date_range_data_extractor.DateRangeDataExtractor()\n",
    "data_extractor.extract_data(r'./files/', from_date, to_date)\n",
    "data = data_extractor.data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Concatenate data and show info"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0b1d73b35a75b7f"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52389144 entries, 0 to 52389143\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   Time    object \n",
      " 1   Value   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 799.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(data, ignore_index=True, join='inner')\n",
    "print(df.info(), end='\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:10:27.452498500Z",
     "start_time": "2023-11-14T12:10:26.467112500Z"
    }
   },
   "id": "b4b0b868419679a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scale data\n",
    "Change the Time value to datetime format and filter the data to whole seconds and remove all other values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35345f6b33960fc5"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Time     Value\n",
      "0  2023-07-01 00:00:00  50.07763\n",
      "1  2023-07-01 00:00:01  50.07575\n",
      "2  2023-07-01 00:00:02  50.07244\n",
      "3  2023-07-01 00:00:03  50.07040\n",
      "4  2023-07-01 00:00:04  50.07193\n",
      "5  2023-07-01 00:00:05  50.06990\n",
      "6  2023-07-01 00:00:06  50.07419\n",
      "7  2023-07-01 00:00:07  50.07456\n",
      "8  2023-07-01 00:00:08  50.07545\n",
      "9  2023-07-01 00:00:09  50.08005\n",
      "10 2023-07-01 00:00:10  50.08031\n",
      "11 2023-07-01 00:00:11  50.08071\n",
      "12 2023-07-01 00:00:12  50.08263\n",
      "13 2023-07-01 00:00:13  50.08107\n",
      "14 2023-07-01 00:00:14  50.07819\n",
      "15 2023-07-01 00:00:15  50.07428\n",
      "16 2023-07-01 00:00:16  50.06272\n",
      "17 2023-07-01 00:00:17  50.05571\n",
      "18 2023-07-01 00:00:18  50.05046\n",
      "19 2023-07-01 00:00:19  50.04753\n"
     ]
    }
   ],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df = df[df['Time'].dt.microsecond == 0]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.head(20))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:11:32.261095900Z",
     "start_time": "2023-11-14T12:11:22.412563700Z"
    }
   },
   "id": "3128bda800186933"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add timezone to data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0d04c2813bbd4a5"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time']).dt.tz_localize('Europe/Helsinki', ambiguous='infer')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:11:35.902539Z",
     "start_time": "2023-11-14T12:11:32.257106700Z"
    }
   },
   "id": "658d4b88334e0c7a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyze integrity of data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7ded2bd4c34f093"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check and drop duplicates if any"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce28ba9a762671f2"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: \n",
      "8\n",
      "                             Time     Value\n",
      "3601    2023-07-01 01:00:00+03:00  49.92183\n",
      "7202    2023-07-01 02:00:00+03:00  50.04779\n",
      "10803   2023-07-01 03:00:00+03:00  50.07014\n",
      "14404   2023-07-01 04:00:00+03:00  49.94890\n",
      "2574519 2023-08-01 01:00:00+03:00  50.10892\n",
      "2578120 2023-08-01 02:00:00+03:00  50.05931\n",
      "2581721 2023-08-01 03:00:00+03:00  50.01276\n",
      "2585322 2023-08-01 04:00:00+03:00  49.90219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duplicated_rows = df[df.duplicated()]\n",
    "num_duplicated = len(duplicated_rows)\n",
    "print(f'Duplicates: \\n{num_duplicated}\\n{duplicated_rows}', end='\\n\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:11:38.319494200Z",
     "start_time": "2023-11-14T12:11:35.906524100Z"
    }
   },
   "id": "518577c5a5102b06"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove duplicates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fce57f047da4c1bd"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:11:40.197308900Z",
     "start_time": "2023-11-14T12:11:38.306528900Z"
    }
   },
   "id": "31c4e11ed626341"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Find duplicates in date"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fcf67165c864fa1"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in Time column: \n",
      "0\n",
      "Empty DataFrame\n",
      "Columns: [Time, Value]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicated_rows_time = df[df.duplicated(subset=\"Time\", keep=False)]\n",
    "num_duplicated_time = len(duplicated_rows_time)\n",
    "print(f'Duplicates in Time column: \\n{num_duplicated_time}\\n{duplicated_rows_time}', end='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:11:40.974525700Z",
     "start_time": "2023-11-14T12:11:40.206301200Z"
    }
   },
   "id": "e4e93e062ea15efd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove duplicates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3abf53207780187a"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='Time')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:11:41.906306100Z",
     "start_time": "2023-11-14T12:11:40.964554Z"
    }
   },
   "id": "d0da198db305f804"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Any NaN, Null, 0 or \"\" found in Value."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0b19c4f8f538a62"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is not a number in value column:: \n",
      "0\n",
      "Is a NULL in value column:: \n",
      "0\n",
      "Zero values in value column: \n",
      "0\n",
      "White spaces in value column: \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "dfNaN = df[df['Value'].isna()]\n",
    "nrNaN = len(dfNaN)\n",
    "dfNull = df[df['Value'].isnull()]\n",
    "nrNull = len(dfNull)\n",
    "dfZeroValues = df[df['Value'] == 0]\n",
    "zeroValues = len(dfZeroValues)\n",
    "dfWhiteSpaces = df[df['Value'] == \"\"]\n",
    "whiteSpaces = len(dfWhiteSpaces)\n",
    "print(f'Is not a number in value column:: \\n{nrNaN}', end='\\n')\n",
    "print(f'Is a NULL in value column:: \\n{nrNull}', end='\\n')\n",
    "print(f'Zero values in value column: \\n{zeroValues}', end='\\n')\n",
    "print(f'White spaces in value column: \\n{whiteSpaces}', end='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:11:41.984101400Z",
     "start_time": "2023-11-14T12:11:41.894338400Z"
    }
   },
   "id": "4420e2005b519f84"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Finding any missing date in the series of dates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3ec566000febccf"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing dates: 2623493\n",
      "\n",
      "\n",
      "                        Time     Value\n",
      "0  2023-07-01 00:00:00+03:00  50.07763\n",
      "1  2023-07-01 00:00:01+03:00  50.07575\n",
      "2  2023-07-01 00:00:02+03:00  50.07244\n",
      "3  2023-07-01 00:00:03+03:00  50.07040\n",
      "4  2023-07-01 00:00:04+03:00  50.07193\n",
      "5  2023-07-01 00:00:05+03:00  50.06990\n",
      "6  2023-07-01 00:00:06+03:00  50.07419\n",
      "7  2023-07-01 00:00:07+03:00  50.07456\n",
      "8  2023-07-01 00:00:08+03:00  50.07545\n",
      "9  2023-07-01 00:00:09+03:00  50.08005\n",
      "10 2023-07-01 00:00:10+03:00  50.08031\n",
      "11 2023-07-01 00:00:11+03:00  50.08071\n",
      "12 2023-07-01 00:00:12+03:00  50.08263\n",
      "13 2023-07-01 00:00:13+03:00  50.08107\n",
      "14 2023-07-01 00:00:14+03:00  50.07819\n",
      "15 2023-07-01 00:00:15+03:00  50.07428\n",
      "16 2023-07-01 00:00:16+03:00  50.06272\n",
      "17 2023-07-01 00:00:17+03:00  50.05571\n",
      "18 2023-07-01 00:00:18+03:00  50.05046\n",
      "19 2023-07-01 00:00:19+03:00  50.04753\n"
     ]
    }
   ],
   "source": [
    "from_date = pd.to_datetime(from_date).tz_localize('Europe/Helsinki')\n",
    "to_date = pd.to_datetime(to_date).tz_localize('Europe/Helsinki')\n",
    "date_range = pd.date_range(start=from_date, end=to_date, freq='S')\n",
    "\n",
    "df.set_index('Time', inplace=True)\n",
    "df = df.reindex(date_range)\n",
    "missingDates = df[df['Value'].isna()].shape[0]\n",
    "print(f'Number of missing dates: {missingDates}', end='\\n\\n\\n')\n",
    "df.reset_index(inplace=True, names=\"Time\")\n",
    "df['Value'].fillna(-1, inplace=True)\n",
    "print(df.head(20))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:11:43.822490Z",
     "start_time": "2023-11-14T12:11:41.960161Z"
    }
   },
   "id": "8419bff775d5037c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cell below to filter out time in a range"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebf8bfab5e30da34"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "# start_time = '2021-12-12 06:00:00'\n",
    "# end_time = '2021-12-12 07:00:00'\n",
    "# start_time = pd.to_datetime(start_time).tz_localize('Europe/Helsinki')\n",
    "# end_time = pd.to_datetime(end_time).tz_localize('Europe/Helsinki')\n",
    "# filtered_data_time = filtered_df[(filtered_df['Time'] >= start_time) & (filtered_df['Time'] <= end_time)]\n",
    "# print(filtered_data_time.head(20))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:11:43.825483200Z",
     "start_time": "2023-11-14T12:11:43.812518500Z"
    }
   },
   "id": "fee5ef0d1b051272"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert to Swedish time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e03a25003ca19247"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Time     Value\n",
      "0  2023-06-30 23:00:00+02:00  50.07763\n",
      "1  2023-06-30 23:00:01+02:00  50.07575\n",
      "2  2023-06-30 23:00:02+02:00  50.07244\n",
      "3  2023-06-30 23:00:03+02:00  50.07040\n",
      "4  2023-06-30 23:00:04+02:00  50.07193\n",
      "5  2023-06-30 23:00:05+02:00  50.06990\n",
      "6  2023-06-30 23:00:06+02:00  50.07419\n",
      "7  2023-06-30 23:00:07+02:00  50.07456\n",
      "8  2023-06-30 23:00:08+02:00  50.07545\n",
      "9  2023-06-30 23:00:09+02:00  50.08005\n",
      "10 2023-06-30 23:00:10+02:00  50.08031\n",
      "11 2023-06-30 23:00:11+02:00  50.08071\n",
      "12 2023-06-30 23:00:12+02:00  50.08263\n",
      "13 2023-06-30 23:00:13+02:00  50.08107\n",
      "14 2023-06-30 23:00:14+02:00  50.07819\n",
      "15 2023-06-30 23:00:15+02:00  50.07428\n",
      "16 2023-06-30 23:00:16+02:00  50.06272\n",
      "17 2023-06-30 23:00:17+02:00  50.05571\n",
      "18 2023-06-30 23:00:18+02:00  50.05046\n",
      "19 2023-06-30 23:00:19+02:00  50.04753\n"
     ]
    }
   ],
   "source": [
    "df['Time'] = df['Time'].dt.tz_convert('Europe/Stockholm')\n",
    "print(df.head(20))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:11:43.952144500Z",
     "start_time": "2023-11-14T12:11:43.823488300Z"
    }
   },
   "id": "3a3b5c1e4223044c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c21e456624cb41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save the data to a new csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c98e1ab88a812cf"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "folder_name = 'processed_files'\n",
    "file_name = output_filename\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "df.to_csv(file_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:13:12.413215Z",
     "start_time": "2023-11-14T12:11:43.907300800Z"
    }
   },
   "id": "92eceeb0d5db51a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save to logfile"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ebeefd6040f2468"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "folder_name = 'log'\n",
    "file_name = 'log.csv'\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "columns = ['Index', 'DateFrom', 'DateTo', 'NULL', 'NaN', 'Exact duplicates', 'Time duplicates', 'Zero Values', 'White Space', 'Added missing dates']\n",
    "\n",
    "new_data = {'Index': output_filename, 'DateFrom': from_date, 'DateTo': to_date, 'NULL': nrNull, 'NaN': nrNaN, 'Exact duplicates': num_duplicated, 'Time duplicates': num_duplicated_time, 'Zero Values': zeroValues, 'White Space': whiteSpaces, 'Added missing dates': missingDates}\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "else:\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "index_exists = (df['Index'] == new_data['Index']).any()\n",
    "\n",
    "if index_exists:\n",
    "    df.loc[df['Index'] == new_data['Index']] = [new_data[col] for col in columns]\n",
    "else:\n",
    "    new_row = pd.DataFrame([new_data], columns=columns)\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "df.to_csv(file_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:13:12.480051300Z",
     "start_time": "2023-11-14T12:13:12.424188200Z"
    }
   },
   "id": "24b9d6dc0210ff17"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "                  Index                   DateFrom                     DateTo  \\\n0   2021-Q1_seconds.csv  2021-01-01 00:00:00+02:00  2021-03-31 00:00:00+03:00   \n1   2021-Q2_seconds.csv  2021-04-01 00:00:00+03:00  2021-06-30 00:00:00+03:00   \n2   2021-Q3_seconds.csv  2021-07-01 00:00:00+03:00  2021-09-30 00:00:00+03:00   \n3   2021-Q4_seconds.csv  2021-10-01 00:00:00+03:00  2021-12-31 00:00:00+02:00   \n4   2022-Q1_seconds.csv  2022-01-01 00:00:00+02:00  2022-03-31 00:00:00+03:00   \n5   2022-Q2_seconds.csv  2022-04-01 00:00:00+03:00  2022-06-30 00:00:00+03:00   \n6   2022-Q3_seconds.csv  2022-07-01 00:00:00+03:00  2022-09-30 00:00:00+03:00   \n7   2022-Q4_seconds.csv  2022-10-01 00:00:00+03:00  2022-12-31 00:00:00+02:00   \n8   2023-Q1_seconds.csv  2023-01-01 00:00:00+02:00  2023-03-31 00:00:00+03:00   \n9   2023-Q2_seconds.csv  2023-04-01 00:00:00+03:00  2023-06-30 00:00:00+03:00   \n10  2023-Q3_seconds.csv  2023-07-01 00:00:00+03:00  2023-09-30 00:00:00+03:00   \n\n    NULL  NaN  Exact duplicates  Time duplicates  Zero Values  White Space  \\\n0      0    0                12                0            0            0   \n1      0    0                11                2            0            0   \n2      0    0                 9                6            0            0   \n3      0    0                12                0            0            0   \n4      0    0                10                4            0            0   \n5      0    0                 5               14            0            0   \n6      0    0                 8                8            0            0   \n7      0    0                10                4            0            0   \n8      0    0                12                0            0            0   \n9      0    0                12                0            0            0   \n10     0    0                 8                0            0            0   \n\n    Added missing dates  \n0                  8299  \n1                  9500  \n2                  3206  \n3                  1762  \n4                128083  \n5                  2847  \n6                  3164  \n7                  1808  \n8                  1364  \n9                  3049  \n10              2623493  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Index</th>\n      <th>DateFrom</th>\n      <th>DateTo</th>\n      <th>NULL</th>\n      <th>NaN</th>\n      <th>Exact duplicates</th>\n      <th>Time duplicates</th>\n      <th>Zero Values</th>\n      <th>White Space</th>\n      <th>Added missing dates</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-Q1_seconds.csv</td>\n      <td>2021-01-01 00:00:00+02:00</td>\n      <td>2021-03-31 00:00:00+03:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8299</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-Q2_seconds.csv</td>\n      <td>2021-04-01 00:00:00+03:00</td>\n      <td>2021-06-30 00:00:00+03:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-Q3_seconds.csv</td>\n      <td>2021-07-01 00:00:00+03:00</td>\n      <td>2021-09-30 00:00:00+03:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3206</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-Q4_seconds.csv</td>\n      <td>2021-10-01 00:00:00+03:00</td>\n      <td>2021-12-31 00:00:00+02:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1762</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-Q1_seconds.csv</td>\n      <td>2022-01-01 00:00:00+02:00</td>\n      <td>2022-03-31 00:00:00+03:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>128083</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2022-Q2_seconds.csv</td>\n      <td>2022-04-01 00:00:00+03:00</td>\n      <td>2022-06-30 00:00:00+03:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2847</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2022-Q3_seconds.csv</td>\n      <td>2022-07-01 00:00:00+03:00</td>\n      <td>2022-09-30 00:00:00+03:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3164</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2022-Q4_seconds.csv</td>\n      <td>2022-10-01 00:00:00+03:00</td>\n      <td>2022-12-31 00:00:00+02:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1808</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2023-Q1_seconds.csv</td>\n      <td>2023-01-01 00:00:00+02:00</td>\n      <td>2023-03-31 00:00:00+03:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1364</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2023-Q2_seconds.csv</td>\n      <td>2023-04-01 00:00:00+03:00</td>\n      <td>2023-06-30 00:00:00+03:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3049</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2023-Q3_seconds.csv</td>\n      <td>2023-07-01 00:00:00+03:00</td>\n      <td>2023-09-30 00:00:00+03:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2623493</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:13:12.511953900Z",
     "start_time": "2023-11-14T12:13:12.476046900Z"
    }
   },
   "id": "60694f23c73820f7"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T12:13:12.530905300Z",
     "start_time": "2023-11-14T12:13:12.500982100Z"
    }
   },
   "id": "f84ae64f47f68bfe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
