{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d793c0a48251aa2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import date_range_data_extractor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56605910302ac169"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0c7e97707f1c9f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y = '2020'\n",
    "quoter = 2\n",
    "last = False\n",
    "\n",
    "if quoter == 1:\n",
    "    Q = ['Q1','01-01','03-31']\n",
    "elif quoter == 2:\n",
    "    Q = ['Q2','04-01','06-30']\n",
    "elif quoter == 3:\n",
    "    Q = ['Q3','07-01','09-30']\n",
    "elif quoter == 4:\n",
    "    Q = ['Q4','10-01','12-31']\n",
    "\n",
    "from_date = f'{Y}-{Q[1]}' # ex: '2021-01-01'\n",
    "to_date = f'{Y}-{Q[2]}' # ex: '2021-03-31'\n",
    "output_filename = f'{Y}-{Q[0]}_seconds.csv' # ex: '2021-Q1_seconds.csv'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c881350b100140f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5c1e8a1ac234188"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract data from csv files.\n",
    "data_extractor = date_range_data_extractor.DateRangeDataExtractor()\n",
    "data_extractor.extract_data(r'./files/', from_date, to_date)\n",
    "data = data_extractor.data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Concatenate data and show info"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0b1d73b35a75b7f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.concat(data, ignore_index=True, join='inner')\n",
    "print(df.info(), end='\\n\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4b0b868419679a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scale data\n",
    "Change the Time value to datetime format and filter the data to whole seconds and remove all other values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35345f6b33960fc5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df = df[df['Time'].dt.microsecond == 0]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.head(5))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3128bda800186933"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add timezone to data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0d04c2813bbd4a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time']).dt.tz_localize('Europe/Helsinki', ambiguous='infer')\n",
    "print(df.head(5))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "658d4b88334e0c7a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add extra hour"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25896d47c8c4f042"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if quoter == 4:\n",
    "    data_extractor_extra = date_range_data_extractor.DateRangeDataExtractor()\n",
    "    data_extractor_extra.extract_data(r'./files/', f'{str(int(Y) + 1)}-01-01', f'{str(int(Y) + 1)}-01-01')\n",
    "    extra_data = data_extractor_extra.data\n",
    "    edf = pd.concat(extra_data, ignore_index=True, join='inner')\n",
    "    edf['Time'] = pd.to_datetime(edf['Time'])\n",
    "    edf = edf[edf['Time'].dt.microsecond == 0]\n",
    "    edf.reset_index(drop=True, inplace=True)\n",
    "    edf['Time'] = pd.to_datetime(edf['Time']).dt.tz_localize('Europe/Helsinki', ambiguous='infer')\n",
    "    edf = edf[edf['Time'] <= f'{str(int(Y) + 1)}-01-01 01:00:00']\n",
    "    df = pd.concat([df, edf])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    print('Skipping!')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dff2772d2e753b1f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e480c1e49e2ad4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyze integrity of data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7ded2bd4c34f093"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check and drop duplicates if any"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce28ba9a762671f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "duplicated_rows = df[df.duplicated()]\n",
    "num_duplicated = len(duplicated_rows)\n",
    "print(f'Duplicates: \\n{num_duplicated}\\n{duplicated_rows}', end='\\n\\n\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "518577c5a5102b06"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove duplicates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fce57f047da4c1bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31c4e11ed626341"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Find duplicates in date"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fcf67165c864fa1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "duplicated_rows_time = df[df.duplicated(subset=\"Time\", keep=False)]\n",
    "num_duplicated_time = len(duplicated_rows_time)\n",
    "print(f'Duplicates in Time column: \\n{num_duplicated_time}\\n{duplicated_rows_time}', end='\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4e93e062ea15efd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove duplicates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3abf53207780187a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='Time')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0da198db305f804"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Any NaN, Null, 0 or \"\" found in Value."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0b19c4f8f538a62"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfNaN = df[df['Value'].isna()]\n",
    "nrNaN = len(dfNaN)\n",
    "dfNull = df[df['Value'].isnull()]\n",
    "nrNull = len(dfNull)\n",
    "dfZeroValues = df[df['Value'] == 0]\n",
    "zeroValues = len(dfZeroValues)\n",
    "dfWhiteSpaces = df[df['Value'] == \"\"]\n",
    "whiteSpaces = len(dfWhiteSpaces)\n",
    "print(f'Is not a number in value column:: \\n{nrNaN}', end='\\n')\n",
    "print(f'Is a NULL in value column:: \\n{nrNull}', end='\\n')\n",
    "print(f'Zero values in value column: \\n{zeroValues}', end='\\n')\n",
    "print(f'White spaces in value column: \\n{whiteSpaces}', end='\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4420e2005b519f84"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Finding any missing date in the series of dates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3ec566000febccf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.set_index('Time', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "390e1b8048ebbef2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from_date_filter = pd.to_datetime(from_date).tz_localize('Europe/Helsinki')\n",
    "\n",
    "if quoter == 4:\n",
    "    to_date_filter = f'{str(int(Y) + 1)}-01-01 01:00:00+02:00'\n",
    "    to_date_filter = pd.to_datetime(to_date_filter).tz_convert('Europe/Helsinki')\n",
    "else:\n",
    "    to_date_filter = pd.to_datetime(to_date).tz_localize('Europe/Helsinki')\n",
    "    to_date_filter = to_date_filter.replace(hour=23, minute=59, second=59)\n",
    "\n",
    "print(from_date_filter,'\\n',to_date_filter)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8419bff775d5037c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "date_range = pd.date_range(start=from_date_filter, end=to_date_filter, freq='S')\n",
    "missingDates = date_range[~date_range.isin(df.index)].value_counts().sum()\n",
    "\n",
    "df = df.reindex(date_range)\n",
    "print(f'Number of missing dates: {missingDates}', end='\\n\\n\\n')\n",
    "df.reset_index(inplace=True, names=\"Time\")\n",
    "df['Value'].fillna(-1, inplace=True)\n",
    "print(df[df['Value']==-1].head(5))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11c01ce38a3399f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if missingDates == (df[df['Value'] == -1].value_counts().sum()):\n",
    "    print('Test Ok')\n",
    "else:\n",
    "    print('Test Failed')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "111543e7e575a57b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert to Swedish time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e03a25003ca19247"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Time'] = df['Time'].dt.tz_convert('Europe/Stockholm')\n",
    "print(df.head(5))\n",
    "print(df.tail(5))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a3b5c1e4223044c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from_date_filter = pd.to_datetime(from_date).tz_localize('Europe/Stockholm')\n",
    "to_date_filter = pd.to_datetime(to_date).tz_localize('Europe/Stockholm')\n",
    "to_date_filter = to_date_filter.replace(hour=23, minute=59, second=59)\n",
    "if quoter == 1:\n",
    "    df = df[(df['Time'] >= from_date_filter) & (df['Time'] <= to_date_filter)]\n",
    "else:\n",
    "    df = df[df['Time'] <= to_date_filter]\n",
    "print(df.head(5))\n",
    "print(df.tail(5))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddf415cd1652f43"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "150278597b9249c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if df.Value.count() == len(date_range) :\n",
    "    print('Test passed')\n",
    "else :\n",
    "    print(df.Value.count() - len(date_range), '\\nOne hour will always be removed if your data contains January (3600 seconds).')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6abd3d0165b67f99"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c21e456624cb41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save the data to a new csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c98e1ab88a812cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folder_name = 'processed_files'\n",
    "file_name = output_filename\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "df.to_csv(file_path, index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92eceeb0d5db51a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save to logfile"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ebeefd6040f2468"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folder_name = 'log'\n",
    "file_name = 'log.csv'\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "columns = ['Index', 'DateFrom', 'DateTo', 'NULL', 'NaN', 'Exact duplicates', 'Time duplicates', 'Zero Values', 'White Space', 'Added missing dates']\n",
    "\n",
    "new_data = {'Index': output_filename, 'DateFrom': from_date, 'DateTo': to_date, 'NULL': nrNull, 'NaN': nrNaN, 'Exact duplicates': num_duplicated, 'Time duplicates': num_duplicated_time, 'Zero Values': zeroValues, 'White Space': whiteSpaces, 'Added missing dates': missingDates}\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    log_df = pd.DataFrame(columns=columns)\n",
    "else:\n",
    "    log_df = pd.read_csv(file_path)\n",
    "\n",
    "index_exists = (log_df['Index'] == new_data['Index']).any()\n",
    "\n",
    "if index_exists:\n",
    "    log_df.loc[log_df['Index'] == new_data['Index']] = [new_data[col] for col in columns]\n",
    "else:\n",
    "    new_row = pd.DataFrame([new_data], columns=columns)\n",
    "    log_df = pd.concat([log_df, new_row], ignore_index=True)\n",
    "\n",
    "log_df.to_csv(file_path, index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24b9d6dc0210ff17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(log_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60694f23c73820f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f84ae64f47f68bfe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
