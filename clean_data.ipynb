{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d793c0a48251aa2"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import date_range_data_extractor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T08:41:49.799282700Z",
     "start_time": "2023-12-08T08:41:49.784319900Z"
    }
   },
   "id": "56605910302ac169"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0c7e97707f1c9f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y = '2022'\n",
    "quoter = 4\n",
    "\n",
    "if quoter == 1:\n",
    "    Q = ['Q1','01-01','03-31']\n",
    "elif quoter == 2:\n",
    "    Q = ['Q2','04-01','06-30']\n",
    "elif quoter == 3:\n",
    "    Q = ['Q3','07-01','09-30']\n",
    "elif quoter == 4:\n",
    "    Q = ['Q4','10-01','12-31']\n",
    "\n",
    "from_date = f'{Y}-{Q[1]}' # ex: '2021-01-01'\n",
    "to_date = f'{Y}-{Q[2]}' # ex: '2021-03-31'\n",
    "output_filename = f'{Y}-{Q[0]}_seconds.csv' # ex: '2021-Q1_seconds.csv'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c881350b100140f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5c1e8a1ac234188"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract data from csv files.\n",
    "data_extractor = date_range_data_extractor.DateRangeDataExtractor()\n",
    "data_extractor.extract_data(r'./files/', from_date, to_date)\n",
    "data = data_extractor.data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Concatenate data and show info"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0b1d73b35a75b7f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.concat(data, ignore_index=True, join='inner')\n",
    "print(df.info(), end='\\n\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4b0b868419679a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scale data\n",
    "Change the Time value to datetime format and filter the data to whole seconds and remove all other values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35345f6b33960fc5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df = df[df['Time'].dt.microsecond == 0]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.head(5))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3128bda800186933"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add timezone to data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0d04c2813bbd4a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time']).dt.tz_localize('Europe/Helsinki', ambiguous='infer')\n",
    "print(df.head(5))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "658d4b88334e0c7a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add extra hour"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25896d47c8c4f042"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if quoter == 4:\n",
    "    data_extractor_extra = date_range_data_extractor.DateRangeDataExtractor()\n",
    "    data_extractor_extra.extract_data(r'./files/', f'{str(int(Y) + 1)}-01-01', f'{str(int(Y) + 1)}-01-01')\n",
    "    extra_data = data_extractor_extra.data\n",
    "    edf = pd.concat(extra_data, ignore_index=True, join='inner')\n",
    "    edf['Time'] = pd.to_datetime(edf['Time'])\n",
    "    edf = edf[edf['Time'].dt.microsecond == 0]\n",
    "    edf.reset_index(drop=True, inplace=True)\n",
    "    edf['Time'] = pd.to_datetime(edf['Time']).dt.tz_localize('Europe/Helsinki', ambiguous='infer')\n",
    "    edf = edf[edf['Time'] <= f'{str(int(Y) + 1)}-01-01 01:00:00']\n",
    "    df = pd.concat([df, edf])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "else:\n",
    "    print('Skipping!')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dff2772d2e753b1f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e480c1e49e2ad4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyze integrity of data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7ded2bd4c34f093"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check and drop duplicates if any"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce28ba9a762671f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "duplicated_rows = df[df.duplicated()]\n",
    "num_duplicated = len(duplicated_rows)\n",
    "print(f'Duplicates: \\n{num_duplicated}\\n{duplicated_rows}', end='\\n\\n\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "518577c5a5102b06"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove duplicates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fce57f047da4c1bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31c4e11ed626341"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Find duplicates in date"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fcf67165c864fa1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "duplicated_rows_time = df[df.duplicated(subset=\"Time\", keep=False)]\n",
    "num_duplicated_time = len(duplicated_rows_time)\n",
    "print(f'Duplicates in Time column: \\n{num_duplicated_time}\\n{duplicated_rows_time}', end='\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4e93e062ea15efd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove duplicates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3abf53207780187a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='Time')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0da198db305f804"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Any NaN, Null, 0 or \"\" found in Value."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0b19c4f8f538a62"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfNaN = df[df['Value'].isna()]\n",
    "nrNaN = len(dfNaN)\n",
    "dfNull = df[df['Value'].isnull()]\n",
    "nrNull = len(dfNull)\n",
    "dfZeroValues = df[df['Value'] == 0]\n",
    "zeroValues = len(dfZeroValues)\n",
    "dfWhiteSpaces = df[df['Value'] == \"\"]\n",
    "whiteSpaces = len(dfWhiteSpaces)\n",
    "print(f'Is not a number in value column:: \\n{nrNaN}', end='\\n')\n",
    "print(f'Is a NULL in value column:: \\n{nrNull}', end='\\n')\n",
    "print(f'Zero values in value column: \\n{zeroValues}', end='\\n')\n",
    "print(f'White spaces in value column: \\n{whiteSpaces}', end='\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4420e2005b519f84"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Finding any missing date in the series of dates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3ec566000febccf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.set_index('Time', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "390e1b8048ebbef2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from_date_filter = pd.to_datetime(from_date).tz_localize('Europe/Helsinki')\n",
    "\n",
    "if quoter == 4:\n",
    "    to_date_filter = f'{str(int(Y) + 1)}-01-01 01:00:00+02:00'\n",
    "    to_date_filter = pd.to_datetime(to_date_filter).tz_convert('Europe/Helsinki')\n",
    "else:\n",
    "    to_date_filter = pd.to_datetime(to_date).tz_localize('Europe/Helsinki')\n",
    "    to_date_filter = to_date_filter.replace(hour=23, minute=59, second=59)\n",
    "\n",
    "print(from_date_filter,'\\n',to_date_filter)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8419bff775d5037c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "date_range = pd.date_range(start=from_date_filter, end=to_date_filter, freq='S')\n",
    "missingSeconds = date_range[~date_range.isin(df.index)].value_counts().sum()\n",
    "\n",
    "df = df.reindex(date_range)\n",
    "print(f'Number of missing seconds: {missingSeconds}', end='\\n\\n\\n')\n",
    "df.reset_index(inplace=True, names=\"Time\")\n",
    "df['Value'].fillna(-1, inplace=True)\n",
    "print(df[df['Value']==-1].head(5))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11c01ce38a3399f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if missingSeconds == (df[df['Value'] == -1].value_counts().sum()):\n",
    "    print('Test Ok')\n",
    "else:\n",
    "    print('Test Failed')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "111543e7e575a57b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert to Swedish time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e03a25003ca19247"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Time'] = df['Time'].dt.tz_convert('Europe/Stockholm')\n",
    "print(df.head(5))\n",
    "print(df.tail(5))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a3b5c1e4223044c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from_date_filter = pd.to_datetime(from_date).tz_localize('Europe/Stockholm')\n",
    "to_date_filter = pd.to_datetime(to_date).tz_localize('Europe/Stockholm')\n",
    "to_date_filter = to_date_filter.replace(hour=23, minute=59, second=59)\n",
    "if quoter == 1:\n",
    "    df = df[(df['Time'] >= from_date_filter) & (df['Time'] <= to_date_filter)]\n",
    "else:\n",
    "    df = df[df['Time'] <= to_date_filter]\n",
    "print(df.head(5))\n",
    "print(df.tail(5))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddf415cd1652f43"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "150278597b9249c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_time_length = df.Value.count() - len(date_range)\n",
    "if test_time_length == 0 :\n",
    "    print('Test passed')\n",
    "else :\n",
    "    print(test_time_length, '\\nOne hour will always be removed if your data contains January (3600 seconds).')\n",
    "    raise RuntimeWarning(f'Value is suppose to be 0 but is: {test_time_length}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6abd3d0165b67f99"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c21e456624cb41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save the data to a new csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c98e1ab88a812cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folder_name = 'processed_files'\n",
    "file_name = output_filename\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "df.to_csv(file_path, index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92eceeb0d5db51a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save to logfile"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ebeefd6040f2468"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "folder_name = 'log'\n",
    "file_name = 'log.csv'\n",
    "file_path = os.path.join(folder_name, file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T08:42:08.736675300Z",
     "start_time": "2023-12-08T08:42:08.697744100Z"
    }
   },
   "id": "2a46ef367da1a8a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "columns = ['Index', 'DateFrom', 'DateTo', 'NULL', 'NaN', 'Exact duplicates', 'Time duplicates', 'Zero Values', 'White Space', 'Added missing seconds']\n",
    "\n",
    "new_data = {'Index': output_filename, 'DateFrom': from_date, 'DateTo': to_date, 'NULL': nrNull, 'NaN': nrNaN, 'Exact duplicates': num_duplicated, 'Time duplicates': num_duplicated_time, 'Zero Values': zeroValues, 'White Space': whiteSpaces, 'Added missing seconds': missingSeconds}\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    log_df = pd.DataFrame(columns=columns)\n",
    "else:\n",
    "    log_df = pd.read_csv(file_path)\n",
    "\n",
    "index_exists = (log_df['Index'] == new_data['Index']).any()\n",
    "\n",
    "if index_exists:\n",
    "    log_df.loc[log_df['Index'] == new_data['Index']] = [new_data[col] for col in columns]\n",
    "else:\n",
    "    new_row = pd.DataFrame([new_data], columns=columns)\n",
    "    log_df = pd.concat([log_df, new_row], ignore_index=True)\n",
    "\n",
    "log_df.to_csv(file_path, index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24b9d6dc0210ff17"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                  Index    DateFrom      DateTo  NULL  NaN  Exact duplicates  \\\n0   2020-Q1_seconds.csv  2020-01-01  2020-03-31     0    0                12   \n1   2020-Q2_seconds.csv  2020-04-01  2020-06-30     0    0                 9   \n2   2020-Q3_seconds.csv  2020-07-01  2020-09-30     0    0                 7   \n3   2020-Q4_seconds.csv  2020-10-01  2020-12-31     0    0                13   \n4   2021-Q1_seconds.csv  2021-01-01  2021-03-31     0    0                12   \n5   2021-Q2_seconds.csv  2021-04-01  2021-06-30     0    0                11   \n6   2021-Q3_seconds.csv  2021-07-01  2021-09-30     0    0                 9   \n7   2021-Q4_seconds.csv  2021-10-01  2021-12-31     0    0                13   \n8   2022-Q1_seconds.csv  2022-01-01  2022-03-31     0    0                10   \n9   2022-Q2_seconds.csv  2022-04-01  2022-06-30     0    0                 5   \n10  2022-Q3_seconds.csv  2022-07-01  2022-09-30     0    0                 8   \n11  2022-Q4_seconds.csv  2022-10-01  2022-12-31     0    0                11   \n\n    Time duplicates  Zero Values  White Space  Added missing seconds  \n0                 0            0            0                  11939  \n1                 6            0            0                  17708  \n2                 2            0            0                 536994  \n3                 0            0            0                 119584  \n4                 0            0            0                   8304  \n5                 2            0            0                   9535  \n6                 6            0            0                   3218  \n7                 0            0            0                   1762  \n8                 4            0            0                 128146  \n9                14            0            0                   2859  \n10                8            0            0                   3197  \n11                4            0            0                   1812  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Index</th>\n      <th>DateFrom</th>\n      <th>DateTo</th>\n      <th>NULL</th>\n      <th>NaN</th>\n      <th>Exact duplicates</th>\n      <th>Time duplicates</th>\n      <th>Zero Values</th>\n      <th>White Space</th>\n      <th>Added missing seconds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-Q1_seconds.csv</td>\n      <td>2020-01-01</td>\n      <td>2020-03-31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11939</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-Q2_seconds.csv</td>\n      <td>2020-04-01</td>\n      <td>2020-06-30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17708</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-Q3_seconds.csv</td>\n      <td>2020-07-01</td>\n      <td>2020-09-30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>536994</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-Q4_seconds.csv</td>\n      <td>2020-10-01</td>\n      <td>2020-12-31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>119584</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-Q1_seconds.csv</td>\n      <td>2021-01-01</td>\n      <td>2021-03-31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8304</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2021-Q2_seconds.csv</td>\n      <td>2021-04-01</td>\n      <td>2021-06-30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9535</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2021-Q3_seconds.csv</td>\n      <td>2021-07-01</td>\n      <td>2021-09-30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3218</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2021-Q4_seconds.csv</td>\n      <td>2021-10-01</td>\n      <td>2021-12-31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1762</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2022-Q1_seconds.csv</td>\n      <td>2022-01-01</td>\n      <td>2022-03-31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>128146</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2022-Q2_seconds.csv</td>\n      <td>2022-04-01</td>\n      <td>2022-06-30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2859</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2022-Q3_seconds.csv</td>\n      <td>2022-07-01</td>\n      <td>2022-09-30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3197</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2022-Q4_seconds.csv</td>\n      <td>2022-10-01</td>\n      <td>2022-12-31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1812</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_df = pd.read_csv(file_path)\n",
    "display(log_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T08:42:11.229009Z",
     "start_time": "2023-12-08T08:42:11.174124200Z"
    }
   },
   "id": "60694f23c73820f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f84ae64f47f68bfe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
